{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWikuE_jfMIz",
        "outputId": "d54fcfb0-08fb-4da1-a356-cd26fdcdbbc6"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install tokenizers\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ8yVatwfsgM",
        "outputId": "077edf18-18ba-46e0-e397-e9e17cb4f8a4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-mKDpX0f7La"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tokenizers import BertWordPieceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUpYuuWSf_2P"
      },
      "outputs": [],
      "source": [
        "# ============================================= PREPARING DATASET ======================================================\n",
        "class Sample:\n",
        "    def __init__(self, question, context, id, start_char_idx=None, answer_text=None, all_answers=None):\n",
        "        self.question = question\n",
        "        self.context = context\n",
        "        self.start_char_idx = start_char_idx\n",
        "        self.answer_text = answer_text\n",
        "        self.all_answers = all_answers\n",
        "        self.skip = False\n",
        "        self.start_token_idx = -1\n",
        "        self.end_token_idx = -1\n",
        "        self.id = id\n",
        "        self.over_length = False\n",
        "\n",
        "\n",
        "    def preprocess(self):\n",
        "        context = \" \".join(str(self.context).split())\n",
        "        question = \" \".join(str(self.question).split())\n",
        "        tokenized_context = tokenizer.encode(context)\n",
        "        tokenized_question = tokenizer.encode(question)\n",
        "        if self.answer_text is not None:\n",
        "            answer = \" \".join(str(self.answer_text).split())\n",
        "            end_char_idx = self.start_char_idx + len(answer)\n",
        "            if end_char_idx >= len(context):\n",
        "                self.skip = True\n",
        "                return\n",
        "            is_char_in_ans = [0] * len(context)\n",
        "            for idx in range(self.start_char_idx, end_char_idx):\n",
        "                is_char_in_ans[idx] = 1\n",
        "            ans_token_idx = []\n",
        "            for idx, (start, end) in enumerate(tokenized_context.offsets):\n",
        "                if sum(is_char_in_ans[start:end]) > 0:\n",
        "                    ans_token_idx.append(idx)\n",
        "            if len(ans_token_idx) == 0:\n",
        "                self.skip = True\n",
        "                return\n",
        "            self.start_token_idx = ans_token_idx[0]\n",
        "            self.end_token_idx = ans_token_idx[-1]\n",
        "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
        "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(tokenized_question.ids[1:])\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        \n",
        "        \n",
        "        padding_length = max_seq_length - len(input_ids)\n",
        "        if padding_length > 0:\n",
        "            input_ids = input_ids + ([0] * padding_length)\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        elif padding_length < 0:\n",
        "            self.over_length = True\n",
        "            input_ids = input_ids[:max_seq_length]\n",
        "            attention_mask = attention_mask[:max_seq_length]\n",
        "            token_type_ids = token_type_ids[:max_seq_length]\n",
        "        self.input_word_ids = input_ids\n",
        "        self.input_type_ids = token_type_ids\n",
        "        self.input_mask = attention_mask\n",
        "        self.context_token_to_char = tokenized_context.offsets\n",
        "\n",
        "\n",
        "def create_coqa_examples(raw_data, ExcludeAnswers = False):\n",
        "  coqa_examples = []\n",
        "  for item in raw_data[\"data\"]:\n",
        "      context = item[\"story\"]\n",
        "      idStub = item[\"id\"]\n",
        "      assert len(item[\"questions\"]) == len(item[\"answers\"])\n",
        "      for i in range(len(item[\"questions\"])):\n",
        "        if not ExcludeAnswers:\n",
        "          question = item[\"questions\"][i]\n",
        "          answer = item[\"answers\"][i]\n",
        "          id = str(idStub) + \"_\" + str(question[\"turn_id\"])\n",
        "          assert answer[\"turn_id\"] == question[\"turn_id\"]\n",
        "          all_answers = [answer[\"span_text\"], answer[\"input_text\"]]\n",
        "          coqa_eg = Sample(question[\"input_text\"], context, id, answer[\"span_start\"], answer[\"span_text\"], all_answers)\n",
        "        else:\n",
        "          question = item[\"questions\"][i]\n",
        "          id = str(idStub) + \"_\" + str(question[\"turn_id\"])\n",
        "          coqa_eg = Sample(question[\"input_text\"], context, id)\n",
        "        coqa_eg.preprocess()\n",
        "        coqa_examples.append(coqa_eg)\n",
        "  return coqa_examples\n",
        "\n",
        "\n",
        "def create_squad_examples(raw_data, ExcludeAnswers = False):\n",
        "    squad_examples = []\n",
        "    for item in raw_data[\"data\"]:\n",
        "        for para in item[\"paragraphs\"]:\n",
        "            context = para[\"context\"]\n",
        "            for qa in para[\"qas\"]:\n",
        "                question = qa[\"question\"]\n",
        "                id = qa[\"id\"]\n",
        "                if \"answers\" in qa and not ExcludeAnswers:\n",
        "                    if \"is_impossible\" in qa and qa[\"is_impossible\"] == True:\n",
        "                      answer_text = \"\"\n",
        "                      all_answers = [\"\"]\n",
        "                      start_char_idx = 0\n",
        "                    else:\n",
        "                      answer_text = qa[\"answers\"][0][\"text\"]\n",
        "                      all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
        "                      start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
        "                    squad_eg = Sample(question, context, id, start_char_idx, answer_text, all_answers)\n",
        "                else:\n",
        "                    squad_eg = Sample(question, context, id)\n",
        "                squad_eg.preprocess()\n",
        "                squad_examples.append(squad_eg)\n",
        "    return squad_examples\n",
        "\n",
        "def create_inputs_targets(squad_examples):\n",
        "    dataset_dict = {\n",
        "        \"input_word_ids\": [],\n",
        "        \"input_type_ids\": [],\n",
        "        \"input_mask\": [],\n",
        "        \"start_token_idx\": [],\n",
        "        \"end_token_idx\": [],\n",
        "    }\n",
        "    for item in squad_examples:\n",
        "        if item.skip == False:\n",
        "            for key in dataset_dict:\n",
        "                dataset_dict[key].append(getattr(item, key))\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "    x = [dataset_dict[\"input_word_ids\"],\n",
        "         dataset_dict[\"input_mask\"],\n",
        "         dataset_dict[\"input_type_ids\"]]\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5LLT_5pgCNK"
      },
      "outputs": [],
      "source": [
        "# =================================================== TRAINING =========================================================\n",
        "\n",
        "\n",
        "class ValidationCallback(keras.callbacks.Callback):\n",
        "\n",
        "    def normalize_text(self, text):\n",
        "        text = text.lower()\n",
        "        text = \"\".join(ch for ch in text if ch not in set(string.punctuation))\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        text = re.sub(regex, \" \", text)\n",
        "        text = \" \".join(text.split())\n",
        "        return text\n",
        "\n",
        "    def __init__(self, x_eval, y_eval):\n",
        "        self.x_eval = x_eval\n",
        "        self.y_eval = y_eval\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
        "        count = 0\n",
        "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "            squad_eg = eval_examples_no_skip[idx]\n",
        "            offsets = squad_eg.context_token_to_char\n",
        "            start = np.argmax(start)\n",
        "            end = np.argmax(end)\n",
        "            if start >= len(offsets):\n",
        "                continue\n",
        "            pred_char_start = offsets[start][0]\n",
        "            if end < len(offsets):\n",
        "                pred_char_end = offsets[end][1]\n",
        "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
        "            else:\n",
        "                pred_ans = squad_eg.context[pred_char_start:]\n",
        "            normalized_pred_ans = self.normalize_text(pred_ans)\n",
        "            normalized_true_ans = [self.normalize_text(_) for _ in squad_eg.all_answers]\n",
        "            if normalized_pred_ans in normalized_true_ans:\n",
        "                count += 1\n",
        "        acc = count / len(self.y_eval[0])\n",
        "        print(f\"\\nepoch={epoch + 1}, exact match score={acc:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBiRMM5vgHKp"
      },
      "outputs": [],
      "source": [
        "\n",
        "max_seq_length = 512\n",
        "\n",
        "Possiblilities = [\"Squad1.1\", \"Squad2.0\", \"CoQA\"]\n",
        "\n",
        "UsedModel = \"Squad2.0\"\n",
        "UsedEvalSet = \"Squad2.0\"\n",
        "if (UsedModel not in Possiblilities or UsedEvalSet not in Possiblilities):\n",
        "   raise NameError(\"Selected model or set not valid\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0mjpLeUgQ7r",
        "outputId": "b7ebe97a-455d-4cd6-9e96-f3a3a0ca24c8"
      },
      "outputs": [],
      "source": [
        "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_word_ids')\n",
        "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_mask')\n",
        "input_type_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_type_ids')\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=True, name=\"bert_en_uncased_L-12_H-768_A-12\")\n",
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy().decode(\"utf-8\")\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertWordPieceTokenizer(vocab=vocab_file, lowercase=True)\n",
        "\n",
        "start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(sequence_output)\n",
        "start_logits = layers.Flatten()(start_logits)\n",
        "end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(sequence_output)\n",
        "end_logits = layers.Flatten()(end_logits)\n",
        "start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
        "end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
        "model = keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=[start_probs, end_probs])\n",
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "optimizer = keras.optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "model.compile(optimizer=optimizer, loss=[loss, loss])\n",
        "model.summary()\n",
        "\n",
        "# Restore the weights\n",
        "print(\"Loading: \", UsedModel)\n",
        "if (UsedModel == \"Squad1.1\"):\n",
        "  model.load_weights(\"/content/gdrive/My Drive/TrainingResults/SQUAD1.1.h5\")\n",
        "elif (UsedModel == \"Squad2.0\"):\n",
        "  model.load_weights(\"/content/gdrive/My Drive/TrainingResults/SQUAD2.0.h5\")\n",
        "elif (UsedModel == \"CoQA\"):\n",
        "  model.load_weights(\"/content/gdrive/My Drive/TrainingResults/CoQA.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W70LrfDUrS6C"
      },
      "outputs": [],
      "source": [
        "def samples_to_predictions(samples):\n",
        "  results = {}\n",
        "  for sample in samples:\n",
        "    if (sample.skip == True):\n",
        "      results[sample.id] = \"\"\n",
        "    if (sample.start_char_idx == -1): # Question predicted as unanswerable\n",
        "      results[sample.id] = \"\"\n",
        "    else:\n",
        "      if (sample.answer_text != None):\n",
        "        results[sample.id] = sample.answer_text\n",
        "      else:\n",
        "        results[sample.id] = \"\"\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojHFG267g_A4",
        "outputId": "2926f1e2-2418-4091-e93e-31bf32f9f93b"
      },
      "outputs": [],
      "source": [
        "# ==================================================== SANITY CHECK =========================================================\n",
        "data = {\"data\":\n",
        "    [\n",
        "        {\"title\": \"Project Apollo\",\n",
        "         \"paragraphs\": [\n",
        "             {\n",
        "                 \"context\": \"The Apollo program, also known as Project Apollo, was the third United States human \"\n",
        "                            \"spaceflight program carried out by the National Aeronautics and Space Administration (\"\n",
        "                            \"NASA), which accomplished landing the first humans on the Moon from 1969 to 1972. First \"\n",
        "                            \"conceived during Dwight D. Eisenhower's administration as a three-man spacecraft to \"\n",
        "                            \"follow the one-man Project Mercury which put the first Americans in space, Apollo was \"\n",
        "                            \"later dedicated to President John F. Kennedy's national goal of landing a man on the \"\n",
        "                            \"Moon and returning him safely to the Earth by the end of the 1960s, which he proposed in \"\n",
        "                            \"a May 25, 1961, address to Congress. Project Mercury was followed by the two-man Project \"\n",
        "                            \"Gemini. The first manned flight of Apollo was in 1968. Apollo ran from 1961 to 1972, \"\n",
        "                            \"and was supported by the two man Gemini program which ran concurrently with it from 1962 \"\n",
        "                            \"to 1966. Gemini missions developed some of the space travel techniques that were \"\n",
        "                            \"necessary for the success of the Apollo missions. Apollo used Saturn family rockets as \"\n",
        "                            \"launch vehicles. Apollo/Saturn vehicles were also used for an Apollo Applications \"\n",
        "                            \"Program, which consisted of Skylab, a space station that supported three manned missions \"\n",
        "                            \"in 1973-74, and the Apollo-Soyuz Test Project, a joint Earth orbit mission with the \"\n",
        "                            \"Soviet Union in 1975.\",\n",
        "                 \"qas\": [\n",
        "                     {\"question\": \"What project put the first Americans into space?\",\n",
        "                      \"id\": \"Q1\"\n",
        "                      },\n",
        "                     {\"question\": \"What program was created to carry out these projects and missions?\",\n",
        "                      \"id\": \"Q2\"\n",
        "                      },\n",
        "                     {\"question\": \"What year did the first manned Apollo flight occur?\",\n",
        "                      \"id\": \"Q3\"\n",
        "                      },\n",
        "                     {\"question\": \"What President is credited with the original notion of putting Americans in space?\",\n",
        "                      \"id\": \"Q4\"\n",
        "                      },\n",
        "                     {\"question\": \"Who did the U.S. collaborate with on an Earth orbit mission in 1975?\",\n",
        "                      \"id\": \"Q5\"\n",
        "                      },\n",
        "                     {\"question\": \"How long did Project Apollo run?\",\n",
        "                      \"id\": \"Q6\"\n",
        "                      },\n",
        "                     {\"question\": \"What program helped develop space travel techniques that Project Apollo used?\",\n",
        "                      \"id\": \"Q7\"\n",
        "                      },\n",
        "                     {\"question\": \"What space station supported three manned missions in 1973-1974?\",\n",
        "                      \"id\": \"Q8\"\n",
        "                      },\n",
        "                      {\"question\": \"Is this question unanswerable?\",\n",
        "                      \"id\": \"Q9\"\n",
        "                      }\n",
        "                 ]}]}]}\n",
        "\n",
        "test_samples = create_squad_examples(data)\n",
        "x_test, _ = create_inputs_targets(test_samples)\n",
        "pred_start, pred_end = model.predict(x_test)\n",
        "for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "  test_sample = test_samples[idx]\n",
        "  offsets = test_sample.context_token_to_char\n",
        "  start = np.argmax(start)\n",
        "  end = np.argmax(end)\n",
        "  pred_ans = None\n",
        "  if start >= len(offsets):\n",
        "    pred_ans = \"Unaswerable\"\n",
        "    pred_char_start = -1\n",
        "  else:    \n",
        "    pred_char_start = offsets[start][0]\n",
        "    if end < len(offsets):\n",
        "      pred_ans = test_sample.context[pred_char_start:offsets[end][1]]\n",
        "    else:\n",
        "      pred_ans = test_sample.context[pred_char_start:offsets[start+2][1]]\n",
        "  print(\"Q: \" + test_sample.question)\n",
        "  print(\"A: \" + pred_ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfTx_yvUiqCb",
        "outputId": "e1704088-a4a2-4248-eaef-19bbef90d176"
      },
      "outputs": [],
      "source": [
        "# ==================================================== PREDICTIONS =========================================================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Loading eval set: \", UsedEvalSet)\n",
        "if (UsedEvalSet == \"CoQA\"):\n",
        "  target_eval_set_path = \"/content/gdrive/My Drive/TrainingResults/TrimmedDevSets/CoQA-dev_Trimmed.json\"\n",
        "elif (UsedEvalSet == \"Squad1.1\"):\n",
        "  target_eval_set_path = \"/content/gdrive/My Drive/TrainingResults/TrimmedDevSets/Squad1.1-dev_Trimmed.json\"\n",
        "elif (UsedEvalSet == \"Squad2.0\"):\n",
        "  target_eval_set_path = \"/content/gdrive/My Drive/TrainingResults/TrimmedDevSets/Squad2.0-dev_Trimmed.json\"\n",
        "with open(target_eval_set_path) as f: EvalData = json.load(f)\n",
        "AllSamples = create_squad_examples(EvalData, True)\n",
        "\n",
        "\n",
        "test_samples = AllSamples\n",
        "print(test_samples[0].context)\n",
        "print(test_samples[0].question)\n",
        "\n",
        "x_test, _ = create_inputs_targets(test_samples)\n",
        "pred_start, pred_end = model.predict(x_test)\n",
        "for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "  test_sample = test_samples[idx]\n",
        "  offsets = test_sample.context_token_to_char\n",
        "  start = np.argmax(start)\n",
        "  end = np.argmax(end)\n",
        "  pred_ans = None\n",
        "  if start >= len(offsets):\n",
        "    pred_ans = \"Unaswerable\"\n",
        "    pred_char_start = -1\n",
        "  else:    \n",
        "    pred_char_start = offsets[start][0]\n",
        "    if end < len(offsets):\n",
        "      pred_ans = test_sample.context[pred_char_start:offsets[end][1]]\n",
        "    else:\n",
        "      pred_ans = test_sample.context[pred_char_start:offsets[start+2][1]]\n",
        "  test_samples[idx].answer_text = pred_ans\n",
        "  test_samples[idx].start_char_idx = pred_char_start\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjqDKan5z2me"
      },
      "outputs": [],
      "source": [
        "#print(samples_to_predictions(test_samples))\n",
        "with open('/content/gdrive/My Drive/TrainingResults/PredictionsV4/'+ UsedModel + '---'+ UsedEvalSet + '-eval-set_Trimmed.json', 'w') as fp:\n",
        "    json.dump(samples_to_predictions(test_samples), fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5uTOocmwr1j"
      },
      "outputs": [],
      "source": [
        "def samples_to_squad_json(samples):\n",
        "  ContextQuestionPairs = {}\n",
        "  for sample in samples:\n",
        "    QAPair = {}\n",
        "    QAPair[\"id\"] = sample.id\n",
        "    QAPair[\"question\"] = sample.question\n",
        "    QAPair[\"answers\"] = []\n",
        "    if (sample.start_char_idx == -1):\n",
        "      QAPair[\"is_impossible\"] = True\n",
        "    else:  \n",
        "      QAPair[\"answers\"].append({\"text\":sample.answer_text, \"answer_start\":sample.start_char_idx })\n",
        "      if (len(sample.all_answers) > 1):\n",
        "        for ans in sample.all_answers:\n",
        "          QAPair[\"answers\"].append({\"text\":ans, \"answer_start\":0 }) # We don't have the answer locations for all_answers, but the eval script does not use this anyway\n",
        "      QAPair[\"is_impossible\"] = False\n",
        "    if sample.context in ContextQuestionPairs:\n",
        "      ContextQuestionPairs[sample.context].append(QAPair)\n",
        "    else:\n",
        "      qas = [QAPair]\n",
        "      ContextQuestionPairs[sample.context] = qas\n",
        "  \n",
        "  raw_data={}\n",
        "  data = []\n",
        "  \n",
        "  for context, qas in ContextQuestionPairs.items():\n",
        "    data.append({\"title\": \"\", \"paragraphs\": [{\"context\": context, \"qas\": qas}]})\n",
        "  raw_data[\"data\"] = data\n",
        "  return raw_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "wx3HUxbBffH5",
        "outputId": "f58e4bbd-b04e-443f-d35f-6666ca21119b"
      },
      "outputs": [],
      "source": [
        "#Stop execution\n",
        "raise NameError(\"Stopped execution\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYQqbqbU6eNZ"
      },
      "outputs": [],
      "source": [
        "def remove_seqlen_exceeding_samples(samples, max_len = 512):\n",
        "  newsamples = []\n",
        "  for sample in samples:\n",
        "    if (sample.over_length == False):\n",
        "      newsamples.append(sample)\n",
        "  return newsamples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iClbtD2Jn4Iw"
      },
      "outputs": [],
      "source": [
        "## Create dev sets where no context exceeds the seqlen\n",
        "\n",
        "eval_path = keras.utils.get_file(\"evalSQUAD1.1.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\")\n",
        "\n",
        "with open('/content/gdrive/My Drive/TrainingResults/TrimmedDevSets/Squad1.1-dev_Trimmed.json', 'w') as fp:\n",
        "  with open(eval_path) as f: raw_eval_data = json.load(f)\n",
        "  json.dump(samples_to_squad_json(remove_seqlen_exceeding_samples(create_squad_examples(raw_eval_data))), fp)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3PNvMQJ6P6m"
      },
      "outputs": [],
      "source": [
        "eval_path = keras.utils.get_file(\"evalSQUAD2.0.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\")\n",
        "\n",
        "with open('/content/gdrive/My Drive/TrainingResults/TrimmedDevSets/Squad2.0-dev_Trimmed.json', 'w') as fp:\n",
        "  with open(eval_path) as f: raw_eval_data = json.load(f)\n",
        "  json.dump(samples_to_squad_json(remove_seqlen_exceeding_samples(create_squad_examples(raw_eval_data))), fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLwB3mBXUU3E"
      },
      "outputs": [],
      "source": [
        "eval_path = keras.utils.get_file(\"evalCoQA.json\", \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\")\n",
        "\n",
        "with open('/content/gdrive/My Drive/TrainingResults/TrimmedDevSets/CoQA-dev_Trimmed.json', 'w') as fp:\n",
        "  with open(eval_path) as f: raw_eval_data = json.load(f)\n",
        "  json.dump(samples_to_squad_json(remove_seqlen_exceeding_samples(create_coqa_examples(raw_eval_data))), fp)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "EvaluationProcedure.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
